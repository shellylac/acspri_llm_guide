---

---


# ğŸ§  Prompt Engineering Frameworks

> â€œFrameworks turn intuition into structure. Prompting is no different â€” a framework lets you reason systematically with language models.â€

This page introduces the most widely used prompt engineering frameworks and shows how to apply them across OpenAI, Gemini, Claude, Hugging Face, and product-level interfaces.

Each section includes:

- âœ… **Core concept**
- ğŸ¯ **Best use cases**
- âŒ **Limitations**
- ğŸ’¡ **Pro tips**
- ğŸ§ª **Implementation example**
- ğŸ›  **Hugging Face Example**
- ğŸ” **Sample Workflow**

---

## ğŸ”¹ Zero-shot Prompting

**Core idea:** Ask the model to perform a task directly, without any examples. Relies on the modelâ€™s general training.

âœ… **Best For:**

- Simple tasks (summarisation, classification, Q&A)
- Rapid prototyping
- When examples are not available

âŒ **Limitations:**

- Prone to hallucination or vague output
- Highly dependent on phrasing
- May not align to task expectations without formatting hints

ğŸ’¡ **Pro Tips:**

- Add structure: â€œRespond in three bullet points.â€
- Use role priming: â€œYou are a...â€
- Be direct with verbs: â€œSummarise, Classify, Extract...â€

ğŸ§ª **Example:**

```text
Summarise this paragraph in three bullet points:

"The new policy proposal aims to reduce urban emissions by 40% by 2030..."
```

ğŸ›  **Hugging Face Implementation:**

```python
from transformers import pipeline
summarizer = pipeline("summarization")
text = "The new policy proposal aims to reduce urban emissions by 40% by 2030..."
summary = summarizer(text, max_length=60, min_length=10, do_sample=False)
```

ğŸ” **Sample Workflow:**

1. Copy/paste text from article, report, policy.
2. Load `summarization` pipeline from HF.
3. Adjust length and sampling.
4. Review and refine format if needed.

---

## ğŸ”¹ Few-shot Prompting

**Core idea:** Provide 1â€“5 example input-output pairs before the actual input to guide the model.

âœ… **Best For:**

- Style imitation
- Classification with nuance
- Custom logic where few examples clarify pattern

âŒ **Limitations:**

- Takes more tokens (context limit concerns)
- Quality of examples heavily affects outcome
- Fragile if formatting is inconsistent

ğŸ’¡ **Pro Tips:**

- Keep format exactly consistent across examples
- Use diverse edge cases if task is complex
- Anchor outputs with clear labels (e.g., â†’ support)

ğŸ§ª **Example:**

```text
Decide if the following quotes express support or opposition:

- "This change is long overdue." â†’ support
- "This will increase our costs unfairly." â†’ oppose

Statement: "This proposal seems rushed and underdeveloped."
```

ğŸ›  **Hugging Face Implementation:**

```python
from transformers import pipeline
classifier = pipeline("text-classification", model="facebook/bart-large-mnli")
classifier("This proposal seems rushed and underdeveloped.")
```

ğŸ” **Sample Workflow:**

1. Manually define few-shot prompt if using OpenAI/Gemini.
2. For HF, simulate few-shot by running examples separately.
3. Use labels for consistent evaluation.
4. Export structured labels for later training.

---

## ğŸ”¹ Chain-of-Thought (CoT)

**Core idea:** Ask the model to show intermediate reasoning steps before answering. This improves performance on complex reasoning tasks.

âœ… **Best For:**

- Logic or math problems
- Policy justification
- Anything requiring rationale or step-by-step explanation

âŒ **Limitations:**

- Output can be verbose
- Reasoning may not be logically valid â€” just fluent

ğŸ’¡ **Pro Tips:**

- Use explicit trigger phrases: â€œLetâ€™s think step by step.â€
- Ask for rationale *before* final answer
- Combine with formatting constraints for control

ğŸ§ª **Example:**

```text
Question: A conference has 120 attendees. Half are from government, and a quarter are from academia. How many are from other sectors?

Letâ€™s think step by step:
1. Half of 120 = 60 (government)
2. A quarter of 120 = 30 (academia)
3. 120 - 60 - 30 = 30 (other sectors)
Final Answer: 30
```

ğŸ›  **Hugging Face Implementation:**

```python
prompt = """
Q: A conference has 120 attendees. Half are from government, and a quarter are from academia. How many are from other sectors?
A: Let's think step by step:
"""

from transformers import pipeline
cot = pipeline("text-generation", model="tiiuae/falcon-7b-instruct")
cot(prompt, max_new_tokens=100)
```

ğŸ” **Sample Workflow:**

1. Embed reasoning scaffold in prompt.
2. Choose model with instruction-tuned weights.
3. Postprocess for final answer extraction.

---

## ğŸ”¹ ReAct (Reasoning + Acting)

**Core idea:** Combine thought traces with external tool usage (e.g., retrieval, calculations, search). Originates from agent-based prompting.

âœ… **Best For:**

- Agents / tool use (LangChain, OpenAI functions)
- Retrieval-Augmented Generation (RAG)
- Multi-hop logic

âŒ **Limitations:**

- Requires framework support (e.g., function calling or memory loop)
- Not universally supported in playgrounds

ğŸ’¡ **Pro Tips:**

- Follow exact format: Thought â†’ Action â†’ Observation â†’ Repeat
- Can chain multiple tools if memory is handled properly

ğŸ§ª **Example:**

```text
Question: Whatâ€™s the population of the capital city of the country where the 2022 FIFA World Cup was held?

Thought: The 2022 World Cup was in Qatar.
Action: Lookup("Capital of Qatar")
Observation: Doha
Action: Lookup("Population of Doha")
Observation: 2.3 million
Final Answer: 2.3 million
```

ğŸ›  **Hugging Face Implementation:** Use LangChain with Hugging Face model and tools:

```python
from langchain.llms import HuggingFacePipeline
from langchain.agents import Tool, initialize_agent
from transformers import pipeline

llm = HuggingFacePipeline(pipeline("text-generation", model="tiiuae/falcon-7b-instruct"))
tools = [Tool.from_function(name="Lookup", func=my_search_function)]
agent = initialize_agent(tools, llm, agent_type="react-description")
agent.run("Whatâ€™s the population of the capital city of the country where the 2022 FIFA World Cup was held?")
```

ğŸ” **Sample Workflow:**

1. Format prompt as ReAct trace
2. Wrap HF model into LangChain agent
3. Bind to external tools (search, DB)

---

## ğŸ”¹ ToT (Tree of Thought)

**Core idea:** Explore multiple reasoning paths in parallel and select the best. Used in advanced orchestration with model voting or branching logic.

âœ… **Best For:**

- High-stakes reasoning (medical, legal, finance)
- Planning or optimization problems

âŒ **Limitations:**

- Not supported in single call; requires orchestrator
- Slower, more compute-heavy

ğŸ’¡ **Pro Tips:**

- Use when multiple â€œcandidateâ€ solutions need comparison
- Combine with prompt templates + scoring heuristics

ğŸ§ª **Example (simplified):**

```text
Task: Suggest the best relocation city based on cost, safety, and opportunity.

Option A: ...
Option B: ...
Option C: ...

Evaluate pros and cons. Choose best.
```

ğŸ›  **Hugging Face Implementation:** Currently requires custom orchestration:

- Generate 3 completions using `num_return_sequences=3`
- Score or filter using a follow-up ranking prompt

ğŸ” **Sample Workflow:**

1. Generate N options with sampling or top-p
2. Prompt LLM again: â€œEvaluate and choose bestâ€
3. Use scoring template to extract winning response

---

## ğŸ§± Framework Summary Table

| Framework | Best For                | Limitations               | Trigger Phrase                   |
| --------- | ----------------------- | ------------------------- | -------------------------------- |
| Zero-shot | Simple tasks            | Prone to vague answers    | â€œSummarise...â€                   |
| Few-shot  | Classification, mimicry | Token cost, brittle       | â€œExample: ...â€                   |
| CoT       | Logic & math            | Verbose, not always valid | â€œLetâ€™s think step by step.â€      |
| ReAct     | Tools + steps           | Needs orchestration       | â€œThought â†’ Action â†’ Observationâ€ |
| ToT       | Complex eval            | Not standalone            | Tree or branch logic             |

---

## ğŸ“ Related Modules

- [Prompt Anatomy â†’](prompt_anatomy.md)
- [Prompt Failures â†’](prompt_failures.md)
- [Evaluation Methods â†’](prompt_evaluation.md)
- [Mini Projects â†’](mini_project_templates.md)

---

