---
id: day1_session2_platforms
title: Day 1 â€“ Session 2: Platform Walkthroughs & API Setup
description: Compare major LLM providers, walk through interface features, and launch your first model calls with real APIs
tags: [session2, api, openai, gemini, huggingface, colab]
status: live
---
![fig_day1_header](../shared_assets/visuals/images/fig_day1_session2_header.png)


# Day 1 â€“ Session 2: Platform Walkthroughs & API Setup

> _"Three platforms. One interface layer. Your job is to learn how to access intelligence across providers â€” safely, precisely, and with full control."_  

---

## ğŸ¯ What Youâ€™ll Learn

âœ… Compare Gemini, OpenAI, and Hugging Face for real-world use  
âœ… Navigate their UI features: extensions, tokens, temperature  
âœ… Set up API keys safely and run your first model calls  
âœ… Prepare for hands-on coding in Colab with multi-provider logic  

---

## ğŸ§­ Structure of This Session

We move from **interface â†’ access â†’ execution** across three major platforms. This is the systems walkthrough youâ€™ll use again and again when working with LLMs.

---

## ğŸŒ Platform Landscape

### ğŸ§© Platform Comparison
[`platform_comparison.md`](../docs/day1/platform_comparison.md)

- Access models: free vs paid
- Modalities: chat, code, vision
- Limits, costs, and provider fit

### ğŸ—ï¸ [API Key Setup](day1/api_key_setup.md)
- How to generate keys for OpenAI, Gemini, and Hugging Face
- Where to store safely in Colab or `.env`

---

## ğŸ–¥ Walkthrough Pages

| Platform | Guide Page | Covers |
|----------|------------|--------|
| ğŸ¤— Hugging Face | [huggingface_walkthrough.md](day1/huggingface_walkthrough.md) | Model hub, pipeline, Spaces |
| ğŸ§  Gemini Studio | [gemini_studio_walkthrough.md](day1/gemini_studio_walkthrough.md) | Extensions, generation modes, code toggle |
| ğŸ” OpenAI Playground | [openai_playground_walkthrough.md](day1/openai_playground_walkthrough.md) | Modes, temperature, stop sequences |

---

## âš™ï¸ First API Calls (Colab)

Youâ€™ll test each platform directly using Python in your browser.

| Notebook | Link | Purpose |
|----------|------|---------|
| `llm_api_test_openai.ipynb` | [Run](https://colab.research.google.com/github/MariaAise/test/blob/main/llm_api_test_openai.ipynb) | ChatCompletion demo |
| `llm_api_test_gemini.ipynb` | [Run](https://colab.research.google.com/github/MariaAise/test/blob/main/llm_api_test_gemini.ipynb) | `generate_content()` call |
| `multi_provider_sandbox.ipynb` | [Run](https://colab.research.google.com/github/MariaAise/test/blob/main/multi_provider_sandbox.ipynb) | Side-by-side comparison |



---

## ğŸ” Modular Code (Reference & Reuse)

These logic blocks are used across the course â€” and in future products.

| Module | Path | Description |
|--------|------|-------------|
| `openai_api_basic_call.md` | `codebook/apis/` | OpenAI call using `ChatCompletion.create()` |
| `gemini_api_basic_call.md` | `codebook/apis/` | Gemini call using Google SDK |
| `hf_inference_api_call.md` | `codebook/apis/` | HF pipeline + REST API |
| `platform_overview.yaml` | `codebook/llm_platforms/` | YAML metadata for limits, cost, speed |

---

## ğŸš§ Troubleshooting

ğŸ“„ [Common API Issues](../../codebook/day1_platforms/troubleshooting_api_errors.md)  
- Invalid key errors  
- SDK mismatch  
- Colab runtime quirks  
- Quota or org-level restrictions

---

## ğŸ§  Reminder: GitBook Architecture

All files in this session live under:

- `gitbook/day1_platforms/`
- `notebooks/Day1_Session2/`
- `codebook/apis/`, `codebook/llm_platforms/`

This ensures your walkthroughs, code, and future product docs remain **modular and reusable**.

---

## ğŸ—‚ Suggested Reading Order

| Step | File | Purpose |
|------|------|---------|
| 1ï¸âƒ£ | `platform_comparison.md` | Understand tradeoffs |
| 2ï¸âƒ£ | `api_key_setup.md` | Set up for execution |
| 3ï¸âƒ£ | `huggingface_walkthrough.md` | Explore HF models |
| 4ï¸âƒ£ | `openai_playground_walkthrough.md` | Understand OpenAI UI |
| 5ï¸âƒ£ | `gemini_studio_walkthrough.md` | Get into Gemini logic |
| 6ï¸âƒ£ | `api_inference_quickstart.md` | Run a basic test |
| 7ï¸âƒ£ | `troubleshooting_api_errors.md` | Fix what breaks |

---

## ğŸ”š Whatâ€™s Next?

â¡ï¸ In **Session 3**, youâ€™ll build on this by crafting and evaluating prompts across tasks: summarisation, classification, Q&A.

â†’ [Session 3: Prompt Architecture & Evaluation â†’](../day1_session3_prompt_architecture.md)

---

## ğŸ”­ Up Next

â¡ï¸ [Session 3: Prompt Engineering + Platform Mastery â†’](day1s3_schedule.md)