---
id: day1_session3_prompt_architecture
title: Day 1 â€“ Session 3: Prompt Engineering + Platform Mastery
description: Learn to structure, debug, and evaluate prompts for LLM workflows across Gemini, OpenAI, and Hugging Face
tags: [prompting, session3, architecture, evaluation, colab, modularity]
status: live
---
![fig_day1_header](../shared_assets/visuals/images/fig_day1_session3_header.png)

# Day 1 â€“ Session 3: Prompt Engineering + Platform Mastery

> _"Prompts are not just inputs â€” they are **architectural decisions**. Today we write systems, not strings."_

---

## ğŸ¯ Session Objectives

âœ… Understand the anatomy and strategy behind well-formed prompts  
âœ… Compare major prompting frameworks: zero-shot, few-shot, CoT, ReAct  
âœ… Identify and debug common prompt failures  
âœ… Evaluate prompt quality using structured and automated methods  
âœ… Apply prompt modularity for reuse across GitBook, MVP, and agents  

---

## ğŸ§  Theory Foundation (GitBook-first)

| Topic | GitBook Page | Purpose |
|-------|--------------|---------|
| ğŸª§ Introduction | [prompting_intro.md](../docs/day1/prompting_intro.md) | Framing prompting as interface logic |
| ğŸ§© Anatomy | [prompt_anatomy.md](../docs/day1/prompt_anatomy.md) | Breaks down instruction/context/examples |
| ğŸ”€ Frameworks | [prompt_frameworks.md](../docs/day1/prompt_frameworks.md) | Zero-shot, Few-shot, CoT, ReAct, ToT |
| ğŸ§¯ Failures | [prompt_failures.md](../docs/day1/prompt_failures.md) | Common failure types + recovery |
| ğŸ§± Modularity | [prompt_modularity.md](../docs/day1/prompt_modularity.md) | Reuse logic for MVP and GitBook |
| ğŸ§ª Evaluation | [prompt_evaluation.md](../docs/day1/prompt_evaluation.md) | Evaluation scores, trace, LLM-as-judge |

---

## ğŸ’» Live Notebook Demo

| Notebook | Purpose | Link |
|----------|---------|------|
| `prompting_sandbox.ipynb` | Side-by-side test on Gemini, GPT-4, HF | [Run in Colab](https://colab.research.google.com/github/MariaAise/test/blob/main/prompting_sandbox.ipynb) |

Features:
- Toggle between prompt types and models
- Capture output differences
- Preview modular architecture for future UI

---

## ğŸ§ª Project & Participant Assets

| File | Purpose | Use |
|------|---------|-----|
| [mini_project_templates.md](day1/mini_project_templates.md) | Homework-style real-world prompt challenges | Leads into independent work |

---

## API Setup

[Gemini API Setup Guide](Gemini_API_Setup_Guide.md)
[Gemini API Setup Guide - screenshots](using_gemini_api_colab.md)

[Hugging Face API Setup Guide](huggingface_api_setup_colab.md)


[OpenAPI Setup Guide](openai_api_setup_colab.md)

---

## ğŸ—‚ Suggested Reading Order

| Step | File | Purpose |
|------|------|---------|
| 1ï¸âƒ£ | `prompting_intro.md` | Session intro and context |
| 2ï¸âƒ£ | `prompt_anatomy.md` | Foundational prompt structure |
| 3ï¸âƒ£ | `prompt_frameworks.md` | Compare prompting methods |
| 4ï¸âƒ£ | `prompt_failures.md` | Learn to debug |
| 5ï¸âƒ£ | `prompt_modularity.md` | Enable strategic reuse |
| 6ï¸âƒ£ | `prompt_evaluation.md` | Score and compare prompt quality |
| 7ï¸âƒ£ | `mini_project_templates.md` | Ready-to-use sector-specific prompts |

---

## ğŸ”® Whatâ€™s Next?

â¡ï¸ On Day 2, we go from prompt-level control to **classification & embeddings** â€” the building blocks of RAG and intelligent agents.

â¡ï¸ [Day 2 â€“ Session 1: Meaning, Similarity & Semantic Drift â†’](day2s1_schedule.md)
